#!/usr/bin/env python3
"""
ØªØ³Øª Ø³Ø§Ø¯Ù‡ Ù…Ù‚Ø§ÛŒØ³Ù‡ LLM Ù‡Ø§
Ø±ÙˆÛŒÚ©Ø±Ø¯: ØªØºÛŒÛŒØ± .env Ùˆ restart service Ø¨Ø±Ø§ÛŒ Ù‡Ø± ØªÙ†Ø¸ÛŒÙ…Ø§Øª

Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ø²Ù…Ø§Ù†: ÙÙ‚Ø· 5 Ø³ÙˆØ§Ù„ Ù†Ù…ÙˆÙ†Ù‡ Ã— 8 ØªÙ†Ø¸ÛŒÙ…Ø§Øª = 40 ØªØ³Øª
"""
import sys
sys.path.insert(0, '/app')

import httpx
import time
import json
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª
CORE_API_URL = "http://localhost:7001"

# 5 Ø³ÙˆØ§Ù„ Ù†Ù…ÙˆÙ†Ù‡ (Ø¨Ù‡ Ø¬Ø§ÛŒ 20)
SAMPLE_QUERIES = [
    'Ù…Ø§Ù„ÛŒØ§Øª Ø¨Ø± Ø§Ø±Ø²Ø´ Ø§ÙØ²ÙˆØ¯Ù‡ Ú†ÛŒØ³Øª Ùˆ Ú†Ú¯ÙˆÙ†Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŸ',
    'Ø­Ù‚ Ø¨ÛŒÙ…Ù‡ ØªØ§Ù…ÛŒÙ† Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ú†Ú¯ÙˆÙ†Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŸ',
    'ØªØ¹Ø±ÙÙ‡ Ú¯Ù…Ø±Ú©ÛŒ Ú†ÛŒØ³Øª Ùˆ Ú†Ú¯ÙˆÙ†Ù‡ ØªØ¹ÛŒÛŒÙ† Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŸ',
    'Ù†Ø±Ø® Ù…Ø§Ù„ÛŒØ§Øª Ø¨Ø± Ø¯Ø±Ø¢Ù…Ø¯ Ø§Ø´Ø®Ø§Øµ Ø­Ù‚ÛŒÙ‚ÛŒ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ',
    'Ø³Ù‡Ù… Ú©Ø§Ø±ÙØ±Ù…Ø§ Ùˆ Ú©Ø§Ø±Ú¯Ø± Ø§Ø² Ø­Ù‚ Ø¨ÛŒÙ…Ù‡ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ',
]

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªØ³Øª - Ø¨Ø±Ø§ÛŒ Ù‡Ø± provider Ùˆ model
TEST_CONFIGS = [
    {'provider': 'GapGPT', 'model': 'gpt-4o-mini', 'note': 'Ø³Ø¨Ú© Ùˆ Ø³Ø±ÛŒØ¹'},
    {'provider': 'GapGPT', 'model': 'gpt-5-mini', 'note': 'Ù†Ø³Ù„ Ø¬Ø¯ÛŒØ¯ Ø³Ø¨Ú©'},
    {'provider': 'GapGPT', 'model': 'gpt-5.1', 'note': 'Ù…ØªÙˆØ³Ø·'},
    {'provider': 'GapGPT', 'model': 'gpt-5.2-chat-latest', 'note': 'Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ†'},
    {'provider': 'OpenAI', 'model': 'gpt-4o-mini', 'note': 'Ø³Ø¨Ú© Ùˆ Ø³Ø±ÛŒØ¹'},
    {'provider': 'OpenAI', 'model': 'gpt-4o', 'note': 'Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯'},
    {'provider': 'OpenAI', 'model': 'gpt-4o', 'note': 'Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯ (ØªÚ©Ø±Ø§Ø±)'},
    {'provider': 'OpenAI', 'model': 'gpt-4o', 'note': 'Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯ (ØªÚ©Ø±Ø§Ø±)'},
]

def create_test_jwt():
    """Ø§ÛŒØ¬Ø§Ø¯ JWT Ø¨Ø±Ø§ÛŒ ØªØ³Øª"""
    from jose import jwt
    from app.config.settings import settings
    
    payload = {
        'sub': 'test_llm_comparison',
        'exp': datetime.now(timezone.utc) + timedelta(hours=2),
        'type': 'access'
    }
    
    token = jwt.encode(payload, settings.jwt_secret_key, algorithm='HS256')
    return token

def test_single_query(query: str, token: str) -> Dict[str, Any]:
    """ØªØ³Øª ÛŒÚ© Ø³ÙˆØ§Ù„"""
    try:
        start = time.time()
        
        response = httpx.post(
            f'{CORE_API_URL}/api/v1/query',
            headers={
                'Authorization': f'Bearer {token}',
                'Content-Type': 'application/json'
            },
            json={
                'query': query,
                'language': 'fa',
                'enable_web_search': False
            },
            timeout=90.0,
            follow_redirects=True
        )
        
        elapsed = (time.time() - start) * 1000
        
        if response.status_code == 200:
            result = response.json()
            return {
                'success': True,
                'total_time_ms': elapsed,
                'processing_time_ms': result.get('processing_time_ms', 0),
                'tokens_used': result.get('tokens_used', 0),
                'input_tokens': result.get('input_tokens', 0),
                'output_tokens': result.get('output_tokens', 0),
                'sources_count': len(result.get('sources', [])),
                'answer_length': len(result.get('answer', ''))
            }
        else:
            return {
                'success': False,
                'error': f'HTTP {response.status_code}',
                'total_time_ms': elapsed
            }
    except httpx.TimeoutException:
        return {'success': False, 'error': 'Timeout'}
    except Exception as e:
        return {'success': False, 'error': str(e)[:100]}

def main():
    print("="*80)
    print("ðŸ”¬ ØªØ³Øª Ø³Ø§Ø¯Ù‡ Ù…Ù‚Ø§ÛŒØ³Ù‡ LLM Ù‡Ø§")
    print("="*80)
    print(f"âš ï¸  Ø§ÛŒÙ† ØªØ³Øª Ø§Ø² ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙØ¹Ù„ÛŒ .env Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯")
    print(f"âš ï¸  Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ú©Ø§Ù…Ù„ØŒ Ø¨Ø§ÛŒØ¯ .env Ø±Ø§ ØªØºÛŒÛŒØ± Ø¯Ø§Ø¯Ù‡ Ùˆ service Ø±Ø§ restart Ú©Ù†ÛŒØ¯")
    print(f"\nØªØ¹Ø¯Ø§Ø¯ Ø³ÙˆØ§Ù„Ø§Øª: {len(SAMPLE_QUERIES)}")
    print(f"Ø´Ø±ÙˆØ¹: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)
    
    # Ø®ÙˆØ§Ù†Ø¯Ù† ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙØ¹Ù„ÛŒ
    from app.config.settings import settings
    
    print(f"\nðŸ“ ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙØ¹Ù„ÛŒ:")
    print(f"   LLM2 Model: {settings.llm2_model}")
    print(f"   LLM2 Provider: {'GapGPT' if 'gapgpt' in settings.llm2_base_url.lower() else 'OpenAI'}")
    print(f"   LLM2 Base URL: {settings.llm2_base_url}")
    
    # Ø§ÛŒØ¬Ø§Ø¯ JWT
    token = create_test_jwt()
    print(f"\nâœ… JWT Token Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
    
    # Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øªâ€ŒÙ‡Ø§
    results = []
    print(f"\nðŸš€ Ø´Ø±ÙˆØ¹ {len(SAMPLE_QUERIES)} ØªØ³Øª...\n")
    
    for i, query in enumerate(SAMPLE_QUERIES, 1):
        print(f"[{i}/{len(SAMPLE_QUERIES)}] {query[:50]}...", end=' ', flush=True)
        
        result = test_single_query(query, token)
        result['query'] = query
        result['query_num'] = i
        result['provider'] = 'GapGPT' if 'gapgpt' in settings.llm2_base_url.lower() else 'OpenAI'
        result['model'] = settings.llm2_model
        results.append(result)
        
        if result['success']:
            print(f"âœ… {result['total_time_ms']:.0f}ms", flush=True)
        else:
            print(f"âŒ {result.get('error', 'Unknown')}", flush=True)
        
        time.sleep(0.5)
    
    # ØªØ­Ù„ÛŒÙ„ Ù†ØªØ§ÛŒØ¬
    successful = [r for r in results if r['success']]
    
    print("\n" + "="*80)
    print("ðŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬")
    print("="*80)
    
    if successful:
        avg_total = sum(r['total_time_ms'] for r in successful) / len(successful)
        avg_proc = sum(r['processing_time_ms'] for r in successful) / len(successful)
        avg_tokens = sum(r['tokens_used'] for r in successful) / len(successful)
        
        print(f"\nâœ… Ù…ÙˆÙÙ‚: {len(successful)}/{len(SAMPLE_QUERIES)}")
        print(f"â±ï¸  Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø²Ù…Ø§Ù† Ú©Ù„: {avg_total:.0f}ms")
        print(f"â±ï¸  Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø²Ù…Ø§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´: {avg_proc:.0f}ms")
        print(f"ðŸŽ« Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ØªÙˆÚ©Ù†: {avg_tokens:.0f}")
    else:
        print("\nâŒ Ù‡Ù…Ù‡ ØªØ³Øªâ€ŒÙ‡Ø§ Ù†Ø§Ù…ÙˆÙÙ‚")
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
    output_data = {
        'config': {
            'provider': 'GapGPT' if 'gapgpt' in settings.llm2_base_url.lower() else 'OpenAI',
            'model': settings.llm2_model,
            'base_url': settings.llm2_base_url
        },
        'timestamp': datetime.now(timezone.utc).isoformat(),
        'results': results
    }
    
    output_file = f'/tmp/llm_test_{settings.llm2_model.replace(".", "_")}.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nðŸ’¾ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± {output_file} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
    
    print("\n" + "="*80)
    print("ðŸ“ Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ ØªØ³Øª Ú©Ø§Ù…Ù„:")
    print("="*80)
    print("""
Ø¨Ø±Ø§ÛŒ ØªØ³Øª ØªÙ…Ø§Ù… ØªØ±Ú©ÛŒØ¨Ø§Øª provider+model:

1. ÙˆÛŒØ±Ø§ÛŒØ´ /srv/.env:
   LLM2_MODEL="gpt-4o-mini"  # ÛŒØ§ gpt-5-mini, gpt-5.1, gpt-5.2-chat-latest
   LLM2_BASE_URL="https://api.gapgpt.ir/v1"  # ÛŒØ§ https://api.openai.com/v1
   LLM2_API_KEY="..."

2. Restart service:
   cd /srv/deployment/docker
   sudo docker compose restart core-api

3. Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø¬Ø¯Ø¯ Ø§ÛŒÙ† ØªØ³Øª:
   sudo docker compose exec core-api python /app/tests/test_llm_comparison_simple.py

4. ØªÚ©Ø±Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù‡Ø± ØªØ±Ú©ÛŒØ¨ provider+model

5. Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ùˆ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†ØªØ§ÛŒØ¬ Ø§Ø² /tmp/llm_test_*.json
""")
    
    return 0 if len(successful) >= len(SAMPLE_QUERIES) * 0.8 else 1

if __name__ == '__main__':
    exit(main())
