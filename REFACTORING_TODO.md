# TODO: Refactoring Tasks

## âœ… Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡:
1. âœ… Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ù…Ø±Ú©Ø²ÛŒ prompts: `/srv/app/config/prompts.py`
2. âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² prompts Ù…Ø±Ú©Ø²ÛŒ Ø¯Ø± `query.py` Ø¨Ø±Ø§ÛŒ `general_no_business`
3. âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² prompts Ù…Ø±Ú©Ø²ÛŒ Ø¯Ø± `query_stream.py` Ø¨Ø±Ø§ÛŒ `general_no_business` Ùˆ `invalid` cases

## ğŸ”„ Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø±:
1. â³ Refactor Ú©Ø±Ø¯Ù† RAG pipeline Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² `RAGPrompts.get_rag_system_prompt_fa()`
   - ÙØ§ÛŒÙ„: `/srv/app/rag/pipeline.py`
   - Ø®Ø·ÙˆØ·: 516-569 (prompt ÙØ§Ø±Ø³ÛŒ)
   - Ø®Ø·ÙˆØ·: 576-615 (prompt Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ)
   - Ø¯Ù„ÛŒÙ„: prompt Ø®ÛŒÙ„ÛŒ Ø¨Ø²Ø±Ú¯ Ø§Ø³Øª Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØ³Øª Ø¯Ù‚ÛŒÙ‚ Ø¯Ø§Ø±Ø¯

2. â³ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² `LLMConfig` Ø¨Ø±Ø§ÛŒ temperature Ùˆ max_tokens
   - ÙØ§ÛŒÙ„â€ŒÙ‡Ø§: `query.py`, `query_stream.py`, `classifier.py`
   - Ù…Ø«Ø§Ù„:
     ```python
     from app.config.prompts import LLMConfig
     
     # Ø¨Ù‡ Ø¬Ø§ÛŒ:
     temperature=0.7
     max_tokens=1000
     
     # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†:
     **LLMConfig.get_config_for_general_questions()
     ```

3. â³ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² `ResponseTemplates` Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
   - Ù…Ø«Ø§Ù„: Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ù…Ù†Ø¨Ø¹ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯
   - Ù…Ø«Ø§Ù„: Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙˆØ¶ÛŒØ­ Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª

## ğŸ“ Ù…Ø²Ø§ÛŒØ§ÛŒ Refactoring Ú©Ø§Ù…Ù„:

### 1. Ù…Ø¯ÛŒØ±ÛŒØª Ù…ØªÙ…Ø±Ú©Ø²
- ØªÙ…Ø§Ù… prompts Ø¯Ø± ÛŒÚ© ÙØ§ÛŒÙ„
- ØªØºÛŒÛŒØ± ÛŒÚ©â€ŒØ¬Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ endpoints
- Ù†Ø³Ø®Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø¢Ø³Ø§Ù†

### 2. A/B Testing
```python
# Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒÙ… Ø¨Ù‡ Ø±Ø§Ø­ØªÛŒ Ù†Ø³Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø±Ø§ ØªØ³Øª Ú©Ù†ÛŒÙ…:
SystemPrompts.get_system_identity_v1()
SystemPrompts.get_system_identity_v2()
```

### 3. Ú†Ù†Ø¯Ø²Ø¨Ø§Ù†Ù‡â€ŒØ³Ø§Ø²ÛŒ
```python
# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø²Ø¨Ø§Ù† Ø¬Ø¯ÛŒØ¯ Ø¢Ø³Ø§Ù† Ø§Ø³Øª:
RAGPrompts.get_rag_system_prompt_fa()  # ÙØ§Ø±Ø³ÛŒ
RAGPrompts.get_rag_system_prompt_en()  # Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
RAGPrompts.get_rag_system_prompt_ar()  # Ø¹Ø±Ø¨ÛŒ (Ø¢ÛŒÙ†Ø¯Ù‡)
```

### 4. Tuning Ø³Ø§Ø¯Ù‡â€ŒØªØ±
```python
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª LLM Ø¯Ø± ÛŒÚ© Ø¬Ø§:
LLMConfig.TEMPERATURE_PRECISE = 0.3
LLMConfig.MAX_TOKENS_LONG = 2000
```

### 5. Ú©Ø§Ù‡Ø´ ØªÚ©Ø±Ø§Ø± Ú©Ø¯
- prompts ØªÚ©Ø±Ø§Ø±ÛŒ Ø­Ø°Ù Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
- Ú©Ø¯ ØªÙ…ÛŒØ²ØªØ± Ùˆ Ù‚Ø§Ø¨Ù„ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒâ€ŒØªØ±

## ğŸ¯ Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒØ¨Ù†Ø¯ÛŒ:

### High Priority (ÙÙˆØ±ÛŒ):
- âœ… System prompts Ø¨Ø±Ø§ÛŒ general questions
- âœ… Invalid prompts

### Medium Priority (Ù…Ù‡Ù…):
- â³ RAG system prompts
- â³ LLM configs

### Low Priority (Ø§Ø®ØªÛŒØ§Ø±ÛŒ):
- â³ Response templates
- â³ Classification keywords

## ğŸ“Š ØªØ£Ø«ÛŒØ±:

| Ù‚Ø¨Ù„ | Ø¨Ø¹Ø¯ |
|-----|-----|
| Prompts Ù¾Ø±Ø§Ú©Ù†Ø¯Ù‡ Ø¯Ø± 5+ ÙØ§ÛŒÙ„ | Prompts Ù…ØªÙ…Ø±Ú©Ø² Ø¯Ø± 1 ÙØ§ÛŒÙ„ |
| ØªØºÛŒÛŒØ± prompt = ØªØºÛŒÛŒØ± Ú†Ù†Ø¯ ÙØ§ÛŒÙ„ | ØªØºÛŒÛŒØ± prompt = ØªØºÛŒÛŒØ± 1 ÙØ§ÛŒÙ„ |
| Hard-coded configs | Centralized configs |
| ØªÚ©Ø±Ø§Ø± Ú©Ø¯ Ø²ÛŒØ§Ø¯ | DRY (Don't Repeat Yourself) |

## ğŸ”§ Ù†Ø­ÙˆÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡:

### Ù…Ø«Ø§Ù„ 1: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² System Prompt
```python
from app.config.prompts import SystemPrompts

# Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ®
current_date_shamsi = "1404/09/10"
current_time_fa = "16:24"

# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² prompt
system_message = SystemPrompts.get_system_identity(
    current_date_shamsi=current_date_shamsi,
    current_time_fa=current_time_fa
)
```

### Ù…Ø«Ø§Ù„ 2: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² LLM Config
```python
from app.config.prompts import LLMConfig

llm_config = LLMConfig(
    provider=LLMProviderEnum.OPENAI_COMPATIBLE,
    model=settings.llm_model,
    api_key=settings.llm_api_key,
    base_url=settings.llm_base_url,
    **LLMConfig.get_config_for_business_questions()  # temperature=0.3, max_tokens=2000
)
```

### Ù…Ø«Ø§Ù„ 3: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Response Template
```python
from app.config.prompts import ResponseTemplates

if not sources:
    return ResponseTemplates.no_sources_found()
```

## âš ï¸ Ù†Ú©Ø§Øª Ù…Ù‡Ù…:

1. **ØªØ³Øª Ú©Ø§Ù…Ù„ Ø¨Ø¹Ø¯ Ø§Ø² Ù‡Ø± ØªØºÛŒÛŒØ±**
   - ØªØ³Øª endpoint Ù‡Ø§ÛŒ non-streaming
   - ØªØ³Øª endpoint Ù‡Ø§ÛŒ streaming
   - ØªØ³Øª RAG pipeline

2. **Backward Compatibility**
   - Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ ØªØºÛŒÛŒØ±Ø§Øª breaking Ù†Ø¨Ø§Ø´Ù†Ø¯
   - API Ù‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ø¨Ø§ÛŒØ¯ Ú©Ø§Ø± Ú©Ù†Ù†Ø¯

3. **Documentation**
   - Ù‡Ø± prompt Ø¨Ø§ÛŒØ¯ docstring Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
   - Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯

## ğŸ“… Timeline Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:

- **Week 1:** âœ… System prompts (Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯)
- **Week 2:** RAG prompts refactoring
- **Week 3:** LLM configs refactoring
- **Week 4:** Response templates + testing

---

**Ø¢Ø®Ø±ÛŒÙ† Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ:** 2025-12-01  
**ÙˆØ¶Ø¹ÛŒØª:** Ø¯Ø± Ø­Ø§Ù„ Ù¾ÛŒØ´Ø±ÙØª (30% Ú©Ø§Ù…Ù„ Ø´Ø¯Ù‡)
