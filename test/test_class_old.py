#!/usr/bin/env python3
"""
ØªØ³Øª Ú©Ù„Ø§Ø³ÛŒÙÛŒÚ©ÛŒØ´Ù† LLM - Ù†Ø³Ø®Ù‡ ØªØ¹Ø§Ù…Ù„ÛŒ
Ù†ØµØ¨: pip install openai
Ø§Ø¬Ø±Ø§: python test_class.py
"""

import json
from openai import OpenAI

# ============================================================================
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª LLM
# ============================================================================
API_KEY = "sk-o92MoYgtEGcJrtvYEPS8t3BTWCwUfdg6o3HzdA67L3yWtddO"
BASE_URL = "https://api.gapgpt.app/v1"

# Ø¯Ùˆ Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡
MODELS = [
    {"name": "gpt-4o-mini", "label": "GPT-4o-mini", "max_tokens": 128},
    {"name": "gpt-5-nano", "label": "GPT-5-nano", "max_tokens": 512},
]

MAX_TOKENS_DEFAULT = 128  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø¯ÙˆÙ† ØªÙ†Ø¸ÛŒÙ… Ø®Ø§Øµ
MAX_TOKENS_RESPONSE = 2048  # Ø¨Ø±Ø§ÛŒ Ù…Ø±Ø­Ù„Ù‡ Ø¯ÙˆÙ… (Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ)
TEMPERATURE = 0.2

# ============================================================================
# Ù¾Ø±Ø§Ù…Ù¾Øª Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ (general) - Ø§Ø² Ú©Ø¯ Ø§ØµÙ„ÛŒ
# ============================================================================

GENERAL_PROMPT = """Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ ÙØ§Ø±Ø³ÛŒâ€ŒØ²Ø¨Ø§Ù† Ù‡Ø³ØªÛŒØ¯.
Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ Ú©Ø§Ø±Ø¨Ø± Ù¾Ø§Ø³Ø® Ø¯Ù‡ÛŒØ¯.

Ù‚ÙˆØ§Ù†ÛŒÙ† Ù…Ù‡Ù…:
1. Ù‡Ø±Ú¯Ø² Ù†Ø§Ù… Ù…Ø¯Ù„ ÛŒØ§ Ø´Ø±Ú©Øª Ø³Ø§Ø²Ù†Ø¯Ù‡ Ø®ÙˆØ¯ Ø±Ø§ ÙØ§Ø´ Ù†Ú©Ù†ÛŒØ¯ (OpenAIØŒ GPTØŒ Claude Ùˆ ØºÛŒØ±Ù‡)
2. Ù‡Ø±Ú¯Ø² Ø¨Ù‡ ØªØ§Ø±ÛŒØ® Ø¢Ù…ÙˆØ²Ø´ ÛŒØ§ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ø´ Ø®ÙˆØ¯ Ø§Ø´Ø§Ø±Ù‡ Ù†Ú©Ù†ÛŒØ¯
3. Ø®ÙˆØ¯ Ø±Ø§ "Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯" Ù…Ø¹Ø±ÙÛŒ Ú©Ù†ÛŒØ¯
4. Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ù…Ø®ØªØµØ±ØŒ Ù…ÙÛŒØ¯ Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ø¨Ø§Ø´Ù†Ø¯
5. Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ Ø®Ø§Ø±Ø¬ Ø§Ø² ØªÙˆØ§Ù†Ø§ÛŒÛŒ Ø´Ù…Ø§Ø³ØªØŒ Ù…ÙˆØ¯Ø¨Ø§Ù†Ù‡ Ø¨Ú¯ÙˆÛŒÛŒØ¯ Ú©Ù‡ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ú©Ù…Ú© Ú©Ù†ÛŒØ¯
6. Ø§Ø² Ø°Ú©Ø± Ø¬Ø²Ø¦ÛŒØ§Øª ÙÙ†ÛŒ Ù…Ø§Ù†Ù†Ø¯ Ù†Ø§Ù… Ù…Ø¯Ù„ØŒ Ù†Ø³Ø®Ù‡ØŒ ØªØ§Ø±ÛŒØ® Ø¢Ù…ÙˆØ²Ø´ Ø®ÙˆØ¯Ø¯Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯"""

# ============================================================================
# Ù¾Ø±Ø§Ù…Ù¾Øª Ú©Ù„Ø§Ø³ÛŒÙÛŒÚ©ÛŒØ´Ù† (ÙØ§Ø±Ø³ÛŒ)
# ============================================================================

CLASSIFICATION_PROMPT_FA = """Ø´Ù…Ø§ ÛŒÚ© "ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø§Ø±Ø´Ø¯ Ù†ÛŒØª Ú©Ø§Ø±Ø¨Ø±" Ù‡Ø³ØªÛŒØ¯. ÙˆØ¸ÛŒÙÙ‡ Ø´Ù…Ø§ ØªØ´Ø®ÛŒØµ Ø¯Ù‚ÛŒÙ‚ Ù‡Ø¯Ù Ú©Ø§Ø±Ø¨Ø± Ùˆ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¢Ù† Ø¯Ø± ÛŒÚ©ÛŒ Ø§Ø² 5 Ú©Ù„Ø§Ø³ Ù…Ø¬Ø§Ø² Ø§Ø³Øª.

Ø¯Ù‚Øª Ø¯Ø± Ø§ÛŒÙ† Ø³ÛŒØ³ØªÙ… Ø­ÛŒØ§ØªÛŒ Ø§Ø³Øª. Ø´Ù…Ø§ Ø¨Ø§ÛŒØ¯ ÙˆØ±ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø± (User Input)ØŒ ØªØ­Ù„ÛŒÙ„ ÙØ§ÛŒÙ„ (File Analysis) Ùˆ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡ (Context) Ø±Ø§ Ù‡Ù…Ø²Ù…Ø§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ù†ÛŒØ¯.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â—„ Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒØ¨Ù†Ø¯ÛŒ ØªØ­Ù„ÛŒÙ„ (Decision Logic) â–º

Ø¨Ø±Ø§ÛŒ Ø±Ø³ÛŒØ¯Ù† Ø¨Ù‡ Ù¾Ø§Ø³Ø® Ø¯Ù‚ÛŒÙ‚ØŒ Ø§ÛŒÙ† Ù…Ø±Ø§Ø­Ù„ Ø°Ù‡Ù†ÛŒ Ø±Ø§ Ø·ÛŒ Ú©Ù†:
1. **Ø¨Ø±Ø±Ø³ÛŒ Context:** Ø¢ÛŒØ§ Ø§ÛŒÙ† ÛŒÚ© Ø³ÙˆØ§Ù„ Ø§Ø¯Ø§Ù…Ù‡â€ŒØ¯Ø§Ø± (Follow-up) Ø§Ø³ØªØŸ (Ù…Ø«Ù„Ø§Ù‹ "Ú†Ø±Ø§ØŸ" ÛŒØ§ "Ø¨ÛŒØ´ØªØ± ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡"). Ø§Ú¯Ø± Ø¨Ù„Ù‡ØŒ Ù…ÙˆØ¶ÙˆØ¹ Ù¾ÛŒØ§Ù… Ù‚Ø¨Ù„ÛŒ Ø±Ø§ Ù…Ù„Ø§Ú© Ù‚Ø±Ø§Ø± Ø¨Ø¯Ù‡.
2. **Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„:** Ø¢ÛŒØ§ Ú©Ø§Ø±Ø¨Ø± ÙØ§ÛŒÙ„ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù‡ØŸ Ø¢ÛŒØ§ ÙØ§ÛŒÙ„ Ø·Ø¨Ù‚ "ØªØ­Ù„ÛŒÙ„ ÙØ§ÛŒÙ„" Ù…Ø¹Ù†Ø§Ø¯Ø§Ø± Ø§Ø³ØªØŸ
3. **Ø¨Ø±Ø±Ø³ÛŒ Ù…ØªÙ†:** Ø¢ÛŒØ§ Ù…ØªÙ† Ø­Ø§ÙˆÛŒ ÙˆØ§Ú˜Ú¯Ø§Ù† ØªØ®ØµØµÛŒ Ú©Ø³Ø¨â€ŒÙˆÚ©Ø§Ø± Ø§Ø³Øª ÛŒØ§ Ø¹Ù…ÙˆÙ…ÛŒØŸ

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â—„ Ù…Ø¹Ø±ÙÛŒ Ø¯Ù‚ÛŒÙ‚ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ â–º

### **1. invalid_no_file** (Ù…ØªÙ† Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø¯ÙˆÙ† ÙØ§ÛŒÙ„)
*   **ØªØ¹Ø±ÛŒÙ:** ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù‡ÛŒÚ† Ù…Ø¹Ù†Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ Ù†Ø¯Ø§Ø±Ù†Ø¯ ÛŒØ§ ØµØ±ÙØ§Ù‹ Ù†Ø§Ø³Ø²Ø§ Ù‡Ø³ØªÙ†Ø¯ Ùˆ Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ Ø¶Ù…ÛŒÙ…Ù‡â€ŒØ§ÛŒ Ù†Ø¯Ø§Ø±Ù†Ø¯.
*   **Ø´Ø§Ù…Ù„:** ÙØ­Ø§Ø´ÛŒ Ø±Ú©ÛŒÚ©ØŒ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø±Ù†Ø¯ÙˆÙ… ("fsdjkl")ØŒ Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ø®Ø§Ù„ÛŒØŒ Ø¹Ù„Ø§Ø¦Ù… Ù†Ú¯Ø§Ø±Ø´ÛŒ ØªÙ†Ù‡Ø§.
*   **Ù…Ø±Ø²Ù‡Ø§ÛŒ ØªØ´Ø®ÛŒØµ (Ø®ÛŒÙ„ÛŒ Ù…Ù‡Ù…):**
    *   Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ø³Ù„Ø§Ù… Ú©Ø±Ø¯ Ùˆ Ø¨Ø¹Ø¯ Ø­Ø±ÙˆÙ Ù†Ø§Ù…Ø±Ø¨ÙˆØ· Ø²Ø¯ â† invalid_no_file
    *   Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ù†ÙˆØ´Øª "Ú©Ù…Ú©Ù… Ú©Ù†" (Ú©ÙˆØªØ§Ù‡ Ø§Ù…Ø§ Ù…Ø¹Ù†ÛŒâ€ŒØ¯Ø§Ø±) â† Ø§ÛŒÙ† invalid Ù†ÛŒØ³Øª!
    *   Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡ Ù…Ø«Ù„ "Ø´Ø±ÙˆØ¹ Ú©Ù†"ØŒ "Ø¨Ø±Ø±Ø³ÛŒ"ØŒ "ØªØ³Øª" Ø§Ú¯Ø± Ø¨Ø¯ÙˆÙ† context Ø¨Ø§Ø´Ù†Ø¯ â† invalid_no_file
    *   Ø§Ù…Ø§ Ø§Ú¯Ø± context Ø¯Ø§Ø±Ù†Ø¯ â† Ø¨Ø± Ø§Ø³Ø§Ø³ context Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ù†
*   **Ø§Ù‚Ø¯Ø§Ù…:** Ù¾Ø§Ø³Ø® Ù…Ø³ØªÙ‚ÛŒÙ… Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ø¬Ù‡Øª Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ú©Ø§Ø±Ø¨Ø± Ø¨Ø±Ø§ÛŒ Ø·Ø±Ø­ Ø³ÙˆØ§Ù„ ØµØ­ÛŒØ­.

### **2. invalid_with_file** (Ø§Ø¨Ù‡Ø§Ù… Ø¯Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ø§ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„)
*   **ØªØ¹Ø±ÛŒÙ:** Ú©Ø§Ø±Ø¨Ø± ÙØ§ÛŒÙ„ÛŒ ÙØ±Ø³ØªØ§Ø¯Ù‡ Ø§Ù…Ø§ Ù†ÛŒØª Ø§Ùˆ Ø¯Ø± Ù…ØªÙ† Ù…Ø´Ø®Øµ Ù†ÛŒØ³Øª (Ù…Ø«Ù„Ø§Ù‹ ÙÙ‚Ø· Ù†ÙˆØ´ØªÙ‡ "Ø§ÛŒÙ† Ú†ÛŒÙ‡" ÛŒØ§ "Ø¨Ø¨ÛŒÙ†").
*   **Ø´Ø±Ø· Ú©Ù„ÛŒØ¯ÛŒ:** Ù…Ø§ Ù†Ù…ÛŒâ€ŒØ¯Ø§Ù†ÛŒÙ… Ú©Ø§Ø±Ø¨Ø± Ú†Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡Ø¯ØŒ Ø­ØªÛŒ Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ù…Ø¹Ù†Ø§Ø¯Ø§Ø± Ø¨Ø§Ø´Ø¯.
*   **ØªØ­Ù„ÛŒÙ„ ÙØ§ÛŒÙ„ (has_meaningful_files):**
    *   `true`: Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ø³Ù†Ø¯ØŒ ÙØ§Ú©ØªÙˆØ±ØŒ Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ØŒ Ù†Ø§Ù…Ù‡ Ø§Ø¯Ø§Ø±ÛŒØŒ Ø§Ú©Ø³Ù„ Ù…Ø§Ù„ÛŒ ÛŒØ§ ØªØµÙˆÛŒØ± Ø§Ø³Ù†Ø§Ø¯ Ø§Ø³Øª.
    *   `false`: Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ø¹Ú©Ø³ Ø³Ù„ÙÛŒØŒ Ù…Ù†Ø¸Ø±Ù‡ØŒ ÙØ§ÛŒÙ„ Ø®Ø±Ø§Ø¨ ÛŒØ§ Ù†Ø§Ù…Ø±Ø¨ÙˆØ· Ø§Ø³Øª.
*   **Ù†Ú©ØªÙ‡ Ø¸Ø±ÛŒÙ:** Ø§Ú¯Ø± Ù…ØªÙ† Ú©Ø§Ø±Ø¨Ø± Ø¯Ù‚ÛŒÙ‚ Ø¨Ø§Ø´Ø¯ (Ù…Ø«Ù„Ø§Ù‹ "Ø®Ù„Ø§ØµÙ‡ Ø§ÛŒÙ† Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ø±Ø§ Ø¨Ú¯Ùˆ")ØŒ Ø§ÛŒÙ† Ø¯Ø³ØªÙ‡ Ø§Ù†ØªØ®Ø§Ø¨ **Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯** (Ø¨Ù‡ Ø¯Ø³ØªÙ‡ 5 Ø¨Ø±ÙˆÛŒØ¯). Ø§ÛŒÙ† Ø¯Ø³ØªÙ‡ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø§Ø³Øª Ú©Ù‡ Ù…ØªÙ† Ú©Ø§Ø±Ø¨Ø± **Ù…Ø¨Ù‡Ù…** Ø§Ø³Øª.
*   **Ø§Ù‚Ø¯Ø§Ù…:** Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ ÙØ§ÛŒÙ„ØŒ Ø³ÙˆØ§Ù„ Ù‡ÙˆØ´Ù…Ù†Ø¯Ø§Ù†Ù‡ Ø¨Ù¾Ø±Ø³.

### **3. general** (Ø¹Ù…ÙˆÙ…ÛŒ / ØºÛŒØ±ØªØ®ØµØµÛŒ)
*   **ØªØ¹Ø±ÛŒÙ:** Ù‡Ø± Ù…ÙˆØ¶ÙˆØ¹ÛŒ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¯Ø§Ù†Ø´ ØªØ®ØµØµÛŒ Ø­Ù‚ÙˆÙ‚ÛŒØŒ Ù…Ø§Ù„ÛŒ ÛŒØ§ Ø§Ø¯Ø§Ø±ÛŒ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯.
*   **Ø´Ø§Ù…Ù„:** Ø§Ø­ÙˆØ§Ù„Ù¾Ø±Ø³ÛŒ ("Ø³Ù„Ø§Ù…"ØŒ "Ø®Ø³ØªÙ‡ Ù†Ø¨Ø§Ø´ÛŒØ¯")ØŒ Ø³ÙˆØ§Ù„Ø§Øª Ø¹Ù„Ù…ÛŒØŒ Ù¾Ø²Ø´Ú©ÛŒØŒ ÙˆØ±Ø²Ø´ÛŒØŒ Ø¢Ø´Ù¾Ø²ÛŒØŒ Ø¬ÙˆÚ©ØŒ ØªØ±Ø¬Ù…Ù‡ Ù…ØªÙ† Ø¹Ù…ÙˆÙ…ÛŒ.
*   **Ù…Ø«Ø§Ù„ Ø¨Ø§ ÙØ§ÛŒÙ„:** "Ø§ÛŒÙ† Ø¢Ø²Ù…Ø§ÛŒØ´ Ø®ÙˆÙ† Ù…Ù† Ø§Ø³ØªØŒ ØªØ­Ù„ÛŒÙ„ Ú©Ù†"ØŒ "Ø§ÛŒÙ† Ø¹Ú©Ø³ Ú†ÛŒØ³ØªØŸ"ØŒ "ØªØ±Ø¬Ù…Ù‡ Ú©Ù†" (Ø§Ú¯Ø± Ù…ØªÙ† Ø­Ù‚ÙˆÙ‚ÛŒ Ù†Ø¨Ø§Ø´Ø¯).
*   **Ø§Ù‚Ø¯Ø§Ù…:** Ù¾Ø§Ø³Ø® Ù…Ø³ØªÙ‚ÛŒÙ… Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ (direct_response = nullØŒ Ø³ÛŒØ³ØªÙ… Ø®ÙˆØ¯Ø´ Ù¾Ø§Ø³Ø® Ù…ÛŒâ€ŒØ¯Ù‡Ø¯).

### **4. business_no_file** (ØªØ®ØµØµÛŒ Ú©Ø³Ø¨â€ŒÙˆÚ©Ø§Ø± Ø¨Ø¯ÙˆÙ† ÙØ§ÛŒÙ„)
*   **ØªØ¹Ø±ÛŒÙ:** Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø§Ú©ÙˆØ³ÛŒØ³ØªÙ… Ú©Ø§Ø±ÛŒØŒ Ø­Ù‚ÙˆÙ‚ÛŒØŒ Ù…Ø§Ù„ÛŒ Ùˆ Ø§Ø¯Ø§Ø±ÛŒ Ú©Ù‡ ÙØ§ÛŒÙ„ Ø¶Ù…ÛŒÙ…Ù‡ Ù†Ø¯Ø§Ø±Ù†Ø¯.
*   **Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§:** Ù‚Ø§Ù†ÙˆÙ† Ú©Ø§Ø±ØŒ Ø¨ÛŒÙ…Ù‡ ØªØ§Ù…ÛŒÙ† Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒØŒ Ù…Ø§Ù„ÛŒØ§ØªØŒ Ø§Ø±Ø²Ø´ Ø§ÙØ²ÙˆØ¯Ù‡ØŒ Ø«Ø¨Øª Ø´Ø±Ú©ØªØŒ Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ØŒ Ø³ÙØªÙ‡ØŒ Ú†Ú©ØŒ Ù…Ø±Ø®ØµÛŒØŒ Ø³Ù†ÙˆØ§ØªØŒ Ø¹ÛŒØ¯ÛŒØŒ Ø´Ú©Ø§ÛŒØªØŒ Ø¯Ø§Ø¯Ø®ÙˆØ§Ø³ØªØŒ Ù„Ø§ÛŒØ­Ù‡ØŒ Ø§Ø³ØªØ§Ø±ØªØ§Ù¾ØŒ Ø¨ÛŒØ²ÛŒÙ†Ø³ Ù¾Ù„Ù†ØŒ ØµØ§Ø¯Ø±Ø§ØªØŒ ÙˆØ§Ø±Ø¯Ø§ØªØŒ Ú¯Ù…Ø±Ú©ØŒ Ù…Ø§Ù„Ú©ÛŒØª ÙÚ©Ø±ÛŒØŒ Ø¨Ø±Ù†Ø¯ØŒ Ù¾Ø±ÙˆØ§Ù†Ù‡ Ú©Ø³Ø¨.
*   **ØªØ´Ø®ÛŒØµ Context:**
    *   ÙˆØ±ÙˆØ¯ÛŒ: "Ú†Ø±Ø§ØŸ" | Context: "Ú©Ø§Ø±Ø¨Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù…Ø§Ù„ÛŒØ§Øª Ù¾Ø±Ø³ÛŒØ¯Ù‡" â†’ **business_no_file**
    *   ÙˆØ±ÙˆØ¯ÛŒ: "Ø¨Ø±Ø§Ù… Ø¨Ù†ÙˆÛŒØ³" | Context: Ø¯Ø±Ø®ÙˆØ§Ø³Øª ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ø§Ø±ÛŒ (Ù…Ø«Ù„ Ù†Ø§Ù…Ù‡ Ø§Ø¯Ø§Ø±ÛŒ) â†’ **business_no_file**
*   **Ø§Ù‚Ø¯Ø§Ù…:** direct_response Ø¨Ø§ÛŒØ¯ null Ø¨Ø§Ø´Ø¯.

### **5. business_with_file** (ØªØ®ØµØµÛŒ Ú©Ø³Ø¨â€ŒÙˆÚ©Ø§Ø± Ø¨Ø§ ÙØ§ÛŒÙ„)
*   **ØªØ¹Ø±ÛŒÙ:** Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´ÙØ§Ù Ùˆ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ú©Ø³Ø¨â€ŒÙˆÚ©Ø§Ø± Ú©Ù‡ Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ ÛŒÚ© ÙØ§ÛŒÙ„ Ø§Ø³Øª.
*   **Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ:**
    1. Ø³ÙˆØ§Ù„ Ø¯Ù‚ÛŒÙ‚ + ÙØ§ÛŒÙ„: "Ø¢ÛŒØ§ Ø§ÛŒÙ† Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÛŒ Ø§Ø³ØªØŸ"
    2. Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ + ÙØ§ÛŒÙ„: "Ø§ÛŒÙ† ÙØ§Ú©ØªÙˆØ± Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†" ÛŒØ§ "Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ÛŒÙ† Ø³Ù†Ø¯ Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†".
*   **Ù†Ú©ØªÙ‡ Ù…Ù‡Ù…:** Ø­ØªÛŒ Ø§Ú¯Ø± Ù…ØªÙ† Ú©ÙˆØªØ§Ù‡ Ø¨Ø§Ø´Ø¯ ("Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†") Ø§Ù…Ø§ Ø¯Ø± Context Ù‚Ø¨Ù„ÛŒ Ú©Ø§Ø±Ø¨Ø± Ú¯ÙØªÙ‡ Ø¨Ø§Ø´Ø¯ "Ø§Ù„Ø§Ù† Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯Ù… Ø±Ø§ Ù…ÛŒÙØ±Ø³ØªÙ…"ØŒ Ø¨Ø§ÛŒØ¯ Ø¯Ø± Ø§ÛŒÙ† Ø¯Ø³ØªÙ‡ Ù‚Ø±Ø§Ø± Ú¯ÛŒØ±Ø¯ØŒ Ù†Ù‡ invalid.
*   **Ø§Ù‚Ø¯Ø§Ù…:** direct_response Ø¨Ø§ÛŒØ¯ null Ø¨Ø§Ø´Ø¯.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â—„ Ù‚ÙˆØ§Ù†ÛŒÙ† Ù†Ù‡Ø§ÛŒÛŒ â–º

1. **Ø§ØµÙ„ "ØªÙˆÙ„ÛŒØ¯ Ø³Ù†Ø¯":** Ù‡Ø± Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ Ø¨Ø±Ø§ÛŒ "Ù†ÙˆØ´ØªÙ†"ØŒ "ØªÙ†Ø¸ÛŒÙ… Ú©Ø±Ø¯Ù†" ÛŒØ§ "Ù¾ÛŒØ´â€ŒÙ†ÙˆÛŒØ³ Ú©Ø±Ø¯Ù†" Ù†Ø§Ù…Ù‡ØŒ Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ ÛŒØ§ Ù„Ø§ÛŒØ­Ù‡ØŒ Ù‚Ø·Ø¹Ø§Ù‹ **Business** Ø§Ø³Øª.

2. **Ø§ØµÙ„ "Ø§Ø¨Ù‡Ø§Ù…â€ŒØ²Ø¯Ø§ÛŒÛŒ":** Ø§Ú¯Ø± Ø¨ÛŒÙ† General Ùˆ Business Ø´Ú© Ø¯Ø§Ø´ØªÛŒØŒ Ø§Ú¯Ø± Ù…ÙˆØ¶ÙˆØ¹ Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø­Ù‚ÙˆÙ‚ÛŒ/Ù…Ø§Ù„ÛŒ Ø¯Ø§Ø±Ø¯ØŒ **Business** Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†.

3. **Ù¾Ø§Ø³Ø® Ù…Ø³ØªÙ‚ÛŒÙ… (Direct Response):** ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ 1 Ùˆ 2 ØªÙˆÙ„ÛŒØ¯ Ø´ÙˆØ¯. Ù„Ø­Ù† Ø¨Ø§ÛŒØ¯ Ù…ÙˆØ¯Ø¨Ø§Ù†Ù‡ØŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ù¾Ø°ÛŒØ±Ø§ Ø¨Ø§Ø´Ø¯. Ù‡Ø±Ú¯Ø² Ù†Ú¯Ùˆ "Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù…"ØŒ Ø¨Ú¯Ùˆ "Ø¨Ø±Ø§ÛŒ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ø¨Ù‡ØªØ± Ù„Ø·ÙØ§..."

4. **Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Context:** Ø³ÙˆØ§Ù„Ø§Øª follow-up (Ù…Ø«Ù„ "Ú†Ø±Ø§ØŸ"ØŒ "Ú†Ø·ÙˆØ±ØŸ"ØŒ "Ø¨ÛŒØ´ØªØ±") Ø±Ø§ Ø¨Ø§ context Ù‚Ø¨Ù„ÛŒ ØªÙØ³ÛŒØ± Ú©Ù†.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â—„ Ø®Ø±ÙˆØ¬ÛŒ â–º

Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ÛŒØ¯ **ÙÙ‚Ø· ÛŒÚ© Ø¢Ø¨Ø¬Ú©Øª JSON** Ø¨Ø§Ø´Ø¯ (Ø¨Ø¯ÙˆÙ† ```json ÛŒØ§ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø§Ø¶Ø§ÙÙ‡):

{
  "category": "invalid_no_file | invalid_with_file | general | business_no_file | business_with_file",
  "confidence": 0.0-1.0,
  "direct_response": "Ù…ØªÙ† Ù¾Ø§Ø³Ø® ÛŒØ§ null",
  "has_meaningful_files": true/false/null,
  "needs_clarification": true/false
}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â—„ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ â–º

**Ù…Ø«Ø§Ù„ 1 - invalid_no_file:**
ÙˆØ±ÙˆØ¯ÛŒ: "asdfgh"
ÙØ§ÛŒÙ„: Ù†Ø¯Ø§Ø±Ø¯
Ø®Ø±ÙˆØ¬ÛŒ:
{"category": "invalid_no_file", "confidence": 0.95, "direct_response": "Ø¨Ø§ Ú©Ù…Ø§Ù„ Ù…ÛŒÙ„ Ú©Ù…Ú©ØªØ§Ù† Ù…ÛŒâ€ŒÚ©Ù†Ù…! Ù„Ø·ÙØ§Ù‹ Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø¶Ø­â€ŒØªØ± Ø¨ÛŒØ§Ù† Ú©Ù†ÛŒØ¯.", "has_meaningful_files": null, "needs_clarification": true}

**Ù…Ø«Ø§Ù„ 2 - invalid_with_file:**
ÙˆØ±ÙˆØ¯ÛŒ: "Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†"
ÙØ§ÛŒÙ„: Ø¯Ø§Ø±Ø¯ - ØªØ­Ù„ÛŒÙ„: "Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ú©Ø§Ø±"
Ø®Ø±ÙˆØ¬ÛŒ:
{"category": "invalid_with_file", "confidence": 0.90, "direct_response": "ÙØ§ÛŒÙ„ Ø´Ù…Ø§ ÛŒÚ© Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ú©Ø§Ø± Ø§Ø³Øª. Ú†Ù‡ Ø¬Ù†Ø¨Ù‡â€ŒØ§ÛŒ Ø±Ø§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†Ù…ØŸ", "has_meaningful_files": true, "needs_clarification": true}

**Ù…Ø«Ø§Ù„ 3 - general:**
ÙˆØ±ÙˆØ¯ÛŒ: "Ø³Ù„Ø§Ù…ØŒ ÛŒÚ© Ø¬ÙˆÚ© Ø¨Ú¯Ùˆ"
ÙØ§ÛŒÙ„: Ù†Ø¯Ø§Ø±Ø¯
Ø®Ø±ÙˆØ¬ÛŒ:
{"category": "general", "confidence": 0.98, "direct_response": null, "has_meaningful_files": null, "needs_clarification": false}

**Ù…Ø«Ø§Ù„ 4 - business_no_file:**
ÙˆØ±ÙˆØ¯ÛŒ: "Ù‚Ø§Ù†ÙˆÙ† Ú©Ø§Ø± Ø¯Ø± Ù…ÙˆØ±Ø¯ Ø§Ø®Ø±Ø§Ø¬ Ú†Ù‡ Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯ØŸ"
ÙØ§ÛŒÙ„: Ù†Ø¯Ø§Ø±Ø¯
Ø®Ø±ÙˆØ¬ÛŒ:
{"category": "business_no_file", "confidence": 0.98, "direct_response": null, "has_meaningful_files": null, "needs_clarification": false}

**Ù…Ø«Ø§Ù„ 5 - business_with_file:**
ÙˆØ±ÙˆØ¯ÛŒ: "Ø§ÛŒÙ† Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†"
ÙØ§ÛŒÙ„: Ø¯Ø§Ø±Ø¯ - ØªØ­Ù„ÛŒÙ„: "Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ø®Ø±ÛŒØ¯ Ù…Ù„Ú©"
Ø®Ø±ÙˆØ¬ÛŒ:
{"category": "business_with_file", "confidence": 0.95, "direct_response": null, "has_meaningful_files": true, "needs_clarification": false}

**Ù…Ø«Ø§Ù„ 6 - Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù†ÙˆØ´ØªÙ† Ø³Ù†Ø¯:**
ÙˆØ±ÙˆØ¯ÛŒ: "Ù„Ø§ÛŒØ­Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø±Ø§ÛŒÛŒ Ø¨Ù†ÙˆÛŒØ³"
ÙØ§ÛŒÙ„: Ù†Ø¯Ø§Ø±Ø¯
Ø®Ø±ÙˆØ¬ÛŒ:
{"category": "business_no_file", "confidence": 0.92, "direct_response": null, "has_meaningful_files": null, "needs_clarification": false}

**Ù…Ø«Ø§Ù„ 7 - follow-up:**
ÙˆØ±ÙˆØ¯ÛŒ: "Ú†Ø±Ø§ØŸ"
Context: "Ú©Ø§Ø±Ø¨Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù…Ø§Ù„ÛŒØ§Øª Ù¾Ø±Ø³ÛŒØ¯Ù‡"
Ø®Ø±ÙˆØ¬ÛŒ:
{"category": "business_no_file", "confidence": 0.88, "direct_response": null, "has_meaningful_files": null, "needs_clarification": false}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
**ÙÙ‚Ø· JSON Ø®Ø§Ù„Øµ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†.**"""


def build_user_message(query: str, file_analysis: str = None) -> str:
    """Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø± Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ LLM"""
    parts = []
    parts.append(f"**ÙˆØ±ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø± (User Input):**\n{query}")
    
    if file_analysis:
        parts.append(f"\n**ØªØ­Ù„ÛŒÙ„ ÙØ§ÛŒÙ„ (File Analysis):**\n{file_analysis}")
    else:
        parts.append("\n**ØªØ­Ù„ÛŒÙ„ ÙØ§ÛŒÙ„ (File Analysis):**\nÙØ§ÛŒÙ„ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
    
    parts.append("\n**ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡ (Context):**\nØ§ÛŒÙ† Ø§ÙˆÙ„ÛŒÙ† Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø± Ø§Ø³Øª.")
    return "\n".join(parts)


def classify_chat_api(query: str, file_analysis: str, model: str, max_tokens: int) -> dict:
    """Ú©Ù„Ø§Ø³ÛŒÙÛŒÚ©ÛŒØ´Ù† Ø¨Ø§ Chat Completions API (Ø¨Ø±Ø§ÛŒ gpt-4o-mini)"""
    
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
    user_message = build_user_message(query, file_analysis)
    
    messages = [
        {"role": "system", "content": CLASSIFICATION_PROMPT_FA},
        {"role": "user", "content": user_message}
    ]
    
    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            max_tokens=max_tokens,
            temperature=TEMPERATURE
        )
        
        raw_response = response.choices[0].message.content or ""
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙˆÚ©Ù† Ù…ØµØ±ÙÛŒ
        input_tokens = 0
        output_tokens = 0
        if hasattr(response, 'usage') and response.usage:
            input_tokens = getattr(response.usage, 'prompt_tokens', 0)
            output_tokens = getattr(response.usage, 'completion_tokens', 0)
        
        result = parse_response(raw_response)
        result['input_tokens'] = input_tokens
        result['output_tokens'] = output_tokens
        return result
            
    except Exception as e:
        return {"error": str(e)}


def classify_responses_api(query: str, file_analysis: str, model: str, max_tokens: int) -> dict:
    """Ú©Ù„Ø§Ø³ÛŒÙÛŒÚ©ÛŒØ´Ù† Ø¨Ø§ Responses API (Ø¨Ø±Ø§ÛŒ gpt-5-nano)"""
    
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
    user_message = build_user_message(query, file_analysis)
    
    # ØªØ±Ú©ÛŒØ¨ system prompt Ùˆ user message
    full_input = f"{CLASSIFICATION_PROMPT_FA}\n\n---\n\n{user_message}"
    
    try:
        response = client.responses.create(
            model=model,
            input=full_input,
            reasoning={"effort": "low"},
            text={"verbosity": "low"},
            max_output_tokens=max_tokens,
        )
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ø§Ø² Ù¾Ø§Ø³Ø®
        raw_response = ""
        if hasattr(response, 'output') and response.output:
            for output_item in response.output:
                if hasattr(output_item, 'content') and output_item.content:
                    for content_item in output_item.content:
                        if hasattr(content_item, 'text') and content_item.text:
                            raw_response = content_item.text
                            break
                    if raw_response:
                        break
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙˆÚ©Ù† Ù…ØµØ±ÙÛŒ
        input_tokens = 0
        output_tokens = 0
        if hasattr(response, 'usage') and response.usage:
            # Responses API ÙØ±Ù…Øª Ù…ØªÙØ§ÙˆØª Ø¯Ø§Ø±Ø¯
            input_tokens = getattr(response.usage, 'input_tokens', 0) or getattr(response.usage, 'prompt_tokens', 0)
            output_tokens = getattr(response.usage, 'output_tokens', 0) or getattr(response.usage, 'completion_tokens', 0)
        
        result = parse_response(raw_response)
        result['input_tokens'] = input_tokens
        result['output_tokens'] = output_tokens
        return result
            
    except Exception as e:
        import traceback
        return {"error": str(e), "traceback": traceback.format_exc()}


def parse_response(raw_response: str) -> dict:
    """Ù¾Ø§Ø±Ø³ Ù¾Ø§Ø³Ø® JSON Ø§Ø² LLM"""
    if not raw_response.strip():
        return {"error": "Ù¾Ø§Ø³Ø® Ø®Ø§Ù„ÛŒ Ø§Ø² LLM", "raw": "EMPTY"}
    
    # Ù¾Ø§Ø±Ø³ JSON
    cleaned = raw_response.strip()
    if cleaned.startswith("```json"):
        cleaned = cleaned[7:]
    if cleaned.startswith("```"):
        cleaned = cleaned[3:]
    if cleaned.endswith("```"):
        cleaned = cleaned[:-3]
    cleaned = cleaned.strip()
    
    try:
        data = json.loads(cleaned)
        # ØªØ¨Ø¯ÛŒÙ„ ÙØ±Ù…Øª Ú©ÙˆØªØ§Ù‡ Ø¨Ù‡ ÙØ±Ù…Øª Ú©Ø§Ù…Ù„
        result = {
            "category": data.get("c") or data.get("category", "unknown"),
            "confidence": data.get("p") or data.get("confidence", 0),
            "_raw": raw_response
        }
        return result
    except json.JSONDecodeError as e:
        return {"error": f"JSON Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {e}", "raw": raw_response[:300]}


def classify(query: str, file_analysis: str, model_info: dict) -> dict:
    """Ø§Ù†ØªØ®Ø§Ø¨ API Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¯Ù„"""
    model = model_info['name']
    max_tokens = model_info.get('max_tokens', MAX_TOKENS_DEFAULT)
    
    if "gpt-5" in model:
        return classify_responses_api(query, file_analysis, model, max_tokens)
    else:
        return classify_chat_api(query, file_analysis, model, max_tokens)


# ============================================================================
# Ù…Ø±Ø­Ù„Ù‡ 2: Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ Ø¨Ø§ Ù¾Ø±Ø§Ù…Ù¾Øª general
# ============================================================================

def respond_chat_api(query: str, file_analysis: str, model: str) -> dict:
    """Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ Ø¨Ø§ Chat Completions API"""
    
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
    
    user_content = query
    if file_analysis:
        user_content = f"{query}\n\n[ÙØ§ÛŒÙ„ Ø¶Ù…ÛŒÙ…Ù‡]: {file_analysis}"
    
    messages = [
        {"role": "system", "content": GENERAL_PROMPT},
        {"role": "user", "content": user_content}
    ]
    
    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            max_tokens=MAX_TOKENS_RESPONSE,
            temperature=0.7
        )
        
        answer = response.choices[0].message.content or ""
        
        input_tokens = 0
        output_tokens = 0
        if hasattr(response, 'usage') and response.usage:
            input_tokens = getattr(response.usage, 'prompt_tokens', 0)
            output_tokens = getattr(response.usage, 'completion_tokens', 0)
        
        return {
            "answer": answer,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens
        }
            
    except Exception as e:
        return {"error": str(e)}


def respond_responses_api(query: str, file_analysis: str, model: str) -> dict:
    """Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ Ø¨Ø§ Responses API (Ø¨Ø±Ø§ÛŒ gpt-5-nano)"""
    
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
    
    user_content = query
    if file_analysis:
        user_content = f"{query}\n\n[ÙØ§ÛŒÙ„ Ø¶Ù…ÛŒÙ…Ù‡]: {file_analysis}"
    
    full_input = f"{GENERAL_PROMPT}\n\n---\n\n{user_content}"
    
    try:
        response = client.responses.create(
            model=model,
            input=full_input,
            reasoning={"effort": "low"},
            text={"verbosity": "medium"},
            max_output_tokens=MAX_TOKENS_RESPONSE,
        )
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ø§Ø² Ù¾Ø§Ø³Ø®
        answer = ""
        if hasattr(response, 'output') and response.output:
            for output_item in response.output:
                if hasattr(output_item, 'content') and output_item.content:
                    for content_item in output_item.content:
                        if hasattr(content_item, 'text') and content_item.text:
                            answer = content_item.text
                            break
                    if answer:
                        break
        
        input_tokens = 0
        output_tokens = 0
        if hasattr(response, 'usage') and response.usage:
            input_tokens = getattr(response.usage, 'input_tokens', 0) or getattr(response.usage, 'prompt_tokens', 0)
            output_tokens = getattr(response.usage, 'output_tokens', 0) or getattr(response.usage, 'completion_tokens', 0)
        
        return {
            "answer": answer,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens
        }
            
    except Exception as e:
        import traceback
        return {"error": str(e), "traceback": traceback.format_exc()}


def respond(query: str, file_analysis: str, model_info: dict) -> dict:
    """Ø§Ù†ØªØ®Ø§Ø¨ API Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ"""
    model = model_info['name']
    
    if "gpt-5" in model:
        return respond_responses_api(query, file_analysis, model)
    else:
        return respond_chat_api(query, file_analysis, model)


def print_response(result: dict, model_label: str):
    """Ù†Ù…Ø§ÛŒØ´ Ù¾Ø§Ø³Ø® Ù…Ø¯Ù„"""
    print(f"\nğŸ¤– {model_label}:")
    print("-" * 40)
    
    if "error" in result:
        print(f"   âŒ Ø®Ø·Ø§: {result['error']}")
    else:
        print(f"   â¬…ï¸ ØªÙˆÚ©Ù† ÙˆØ±ÙˆØ¯ÛŒ: {result.get('input_tokens', 0)}")
        print(f"   â¡ï¸ ØªÙˆÚ©Ù† Ø®Ø±ÙˆØ¬ÛŒ: {result.get('output_tokens', 0)}")
        print(f"   ğŸ’¬ Ù¾Ø§Ø³Ø®:\n{result.get('answer', '')}")


def print_result(result: dict, model_label: str):
    """Ù†Ù…Ø§ÛŒØ´ Ù†ØªÛŒØ¬Ù‡ Ú©Ù„Ø§Ø³ÛŒÙÛŒÚ©ÛŒØ´Ù†"""
    print(f"\nğŸ¤– {model_label}:")
    print("-" * 40)
    
    if "error" in result:
        print(f"   âŒ Ø®Ø·Ø§: {result['error']}")
        if result.get('traceback'):
            print(f"   ğŸ“ Traceback: {result['traceback'][:500]}")
    else:
        print(f"   ğŸ“Œ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ: {result.get('category', 'N/A')}")
        print(f"   ğŸ“ˆ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {result.get('confidence', 0)}")
        print(f"   â¬…ï¸ ØªÙˆÚ©Ù† ÙˆØ±ÙˆØ¯ÛŒ: {result.get('input_tokens', 0)}")
        print(f"   â¡ï¸ ØªÙˆÚ©Ù† Ø®Ø±ÙˆØ¬ÛŒ: {result.get('output_tokens', 0)}")
        print(f"   ğŸ“ Ø®Ø§Ù…: {result.get('_raw', '')}")


def main():
    print("=" * 60)
    print("ğŸ§ª ØªØ³Øª Ú©Ù„Ø§Ø³ÛŒÙÛŒÚ©ÛŒØ´Ù† - Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ùˆ Ù…Ø¯Ù„")
    print("=" * 60)
    print(f"LLM: {BASE_URL}")
    print(f"Ù…Ø¯Ù„â€ŒÙ‡Ø§: {', '.join([m['label'] for m in MODELS])}")
    print("-" * 60)
    
    while True:
        print()
        query = input("ğŸ“ Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ (ÛŒØ§ 'exit' Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬): ").strip()
        
        if query.lower() in ['exit', 'quit', 'q']:
            print("ğŸ‘‹ Ø®Ø¯Ø§Ø­Ø§ÙØ¸!")
            break
        
        if not query:
            print("âš ï¸ Ø³ÙˆØ§Ù„ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯.")
            continue
        
        file_path = input("ğŸ“ Ø¢Ø¯Ø±Ø³ ÙØ§ÛŒÙ„ (Enter = Ø¨Ø¯ÙˆÙ† ÙØ§ÛŒÙ„): ").strip()
        
        file_analysis = None
        if file_path:
            file_analysis = f"ÙØ§ÛŒÙ„ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡: {file_path}"
        
        # ========== Ù…Ø±Ø­Ù„Ù‡ 1: Ú©Ù„Ø§Ø³ÛŒÙÛŒÚ©ÛŒØ´Ù† ==========
        print("\n" + "=" * 60)
        print("ğŸ“Š Ù…Ø±Ø­Ù„Ù‡ 1: Ú©Ù„Ø§Ø³ÛŒÙÛŒÚ©ÛŒØ´Ù†")
        print("=" * 60)
        
        for model_info in MODELS:
            print(f"\nâ³ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ {model_info['label']}...")
            result = classify(query, file_analysis, model_info)
            print_result(result, model_info['label'])
        
        # ========== Ù…Ø±Ø­Ù„Ù‡ 2: Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ Ø¨Ø§ Ù¾Ø±Ø§Ù…Ù¾Øª general ==========
        print("\n" + "=" * 60)
        print("ğŸ’¬ Ù…Ø±Ø­Ù„Ù‡ 2: Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ (Ù¾Ø±Ø§Ù…Ù¾Øª generalØŒ max_tokens=2048)")
        print("=" * 60)
        
        for model_info in MODELS:
            print(f"\nâ³ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ Ø¨Ø§ {model_info['label']}...")
            result = respond(query, file_analysis, model_info)
            print_response(result, model_info['label'])
        
        print("\n" + "=" * 60)


if __name__ == "__main__":
    main()
