#!/usr/bin/env python3
"""ØªØ³Øª Ø¬Ø§Ù…Ø¹ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ LLM"""
import sys
sys.path.insert(0, '/app')

import httpx
import time
import json
from datetime import datetime, timezone
from jose import jwt

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª
JWT_SECRET = '4d0y3u2WuICdKEIGY5n5XoHUkIHKE2v9oq9MsfGIWNgqpIdVnxYSSkd2YT3C5fZs'

# Ø¯Ø±ÛŒØ§ÙØª API keys Ø§Ø² settings
from app.config.settings import settings
OPENAI_KEY = settings.llm_fallback_api_key
GAPGPT_KEY = settings.llm1_api_key

# Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØ³Øª
MODELS = ['gpt-5-nano', 'gpt-4o-mini', 'gpt-5-mini', 'gpt-5.1', 'gpt-5.2']
PROVIDERS = {
    'openai': 'https://api.openai.com/v1',
    'gapgpt': 'https://api.gapgpt.app/v1'
}

# Ø³ÙˆØ§Ù„Ø§Øª ØªØ³Øª
CLASSIFICATION_QUERIES = [
    'Ø³Ù„Ø§Ù… Ú†Ø·ÙˆØ±ÛŒØŸ', 'Ø®ÙˆØ¨ÛŒØŸ', 'Ø­Ø§Ù„Øª Ú†Ø·ÙˆØ±Ù‡ØŸ', 'Ú†Ù‡ Ø®Ø¨Ø±ØŸ', 'Ú©Ø¬Ø§ÛŒÛŒØŸ',
    'ØªÙ‡Ø±Ø§Ù† Ù¾Ø§ÛŒØªØ®Øª Ú©Ø¬Ø§Ø³ØªØŸ', 'Ø¢Ø¨ Ùˆ Ù‡ÙˆØ§ Ú†Ø·ÙˆØ±Ù‡ØŸ', 'Ø³Ø§Ø¹Øª Ú†Ù†Ø¯Ù‡ØŸ', 
    'Ø§Ù…Ø±ÙˆØ² Ú†Ù†Ø¯Ù…Ù‡ØŸ', 'ÙØ±Ø¯Ø§ ØªØ¹Ø·ÛŒÙ„Ù‡ØŸ', 'Ø§Ù„Ø§Ù† Ú©Ø¬Ø§ÛŒÛŒØŸ', 'Ú†ÛŒÚ©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†ÛŒØŸ',
    'Ù†Ø§Ù… ØªÙˆ Ú†ÛŒÙ‡ØŸ', 'Ú†Ù†Ø¯ Ø³Ø§Ù„ØªÙ‡ØŸ', 'Ú©ÛŒ ØªÙˆÙ„Ø¯ØªÙ‡ØŸ'
]

GENERAL_QUERIES = [
    'ØªÙ‡Ø±Ø§Ù† Ù¾Ø§ÛŒØªØ®Øª Ú©Ø¯Ø§Ù… Ú©Ø´ÙˆØ± Ø§Ø³ØªØŸ', 'Ù…Ø³Ø§Ø­Øª Ø§ÛŒØ±Ø§Ù† Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ',
    'Ø¬Ù…Ø¹ÛŒØª ØªÙ‡Ø±Ø§Ù† Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ', 'Ø¨Ù„Ù†Ø¯ØªØ±ÛŒÙ† Ú©ÙˆÙ‡ Ø§ÛŒØ±Ø§Ù† Ú©Ø¯Ø§Ù… Ø§Ø³ØªØŸ',
    'Ø¯Ø±ÛŒØ§Ú†Ù‡ Ø§Ø±ÙˆÙ…ÛŒÙ‡ Ú©Ø¬Ø§Ø³ØªØŸ', 'Ø±ÙˆØ¯ Ú©Ø§Ø±ÙˆÙ† Ú©Ø¬Ø§Ø³ØªØŸ', 'Ø®Ù„ÛŒØ¬ ÙØ§Ø±Ø³ Ú©Ø¬Ø§Ø³ØªØŸ',
    'ØµÙ†Ø§ÛŒØ¹ Ø§ÛŒØ±Ø§Ù† Ú†ÛŒØ³ØªØŸ', 'Ù…Ø­ØµÙˆÙ„Ø§Øª Ú©Ø´Ø§ÙˆØ±Ø²ÛŒ Ø§ÛŒØ±Ø§Ù† Ú†ÛŒØ³ØªØŸ',
    'Ø¢Ø¨ Ùˆ Ù‡ÙˆØ§ÛŒ Ø§ÛŒØ±Ø§Ù† Ú†Ú¯ÙˆÙ†Ù‡ Ø§Ø³ØªØŸ', 'ÙØµÙ„â€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ±Ø§Ù† Ú†ÛŒØ³ØªØŸ',
    'Ø²Ø¨Ø§Ù† Ø±Ø³Ù…ÛŒ Ø§ÛŒØ±Ø§Ù† Ú†ÛŒØ³ØªØŸ', 'Ù¾ÙˆÙ„ Ø§ÛŒØ±Ø§Ù† Ú†ÛŒØ³ØªØŸ', 'Ù¾Ø±Ú†Ù… Ø§ÛŒØ±Ø§Ù† Ú†Ù‡ Ø±Ù†Ú¯ÛŒ Ø§Ø³ØªØŸ',
    'Ø³Ø±ÙˆØ¯ Ù…Ù„ÛŒ Ø§ÛŒØ±Ø§Ù† Ú†ÛŒØ³ØªØŸ', 'Ø±ÙˆØ² Ù…Ù„ÛŒ Ø§ÛŒØ±Ø§Ù† Ú†Ù‡ Ø±ÙˆØ²ÛŒ Ø§Ø³ØªØŸ',
    'ØªØ§Ø±ÛŒØ® Ø§ÛŒØ±Ø§Ù† Ú†Ù‚Ø¯Ø± Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ø³ØªØŸ', 'ØªÙ…Ø¯Ù† Ø§ÛŒØ±Ø§Ù† Ú†Ú¯ÙˆÙ†Ù‡ Ø¨ÙˆØ¯ØŸ',
    'Ø´Ø§Ø¹Ø±Ø§Ù† Ø§ÛŒØ±Ø§Ù† Ú©ÛŒâ€ŒØ§Ù†Ø¯ØŸ', 'Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù† Ø§ÛŒØ±Ø§Ù† Ú©ÛŒâ€ŒØ§Ù†Ø¯ØŸ'
]

BUSINESS_QUERIES = [
    'Ø¯Ø± Ù„ÛŒØ³Øª Ø­Ù‚ÙˆÙ‚ Ùˆ Ø¯Ø³ØªÙ…Ø²Ø¯ Ú†Ù†Ø¯ Ø¯Ø±ØµØ¯ Ø¨Ø§Ø¨Øª Ø¨ÛŒÙ…Ù‡ Ø¨ÛŒÚ©Ø§Ø±ÛŒ Ú©Ø³Ø± Ú©Ù†Ù…ØŸ',
    'Ø­Ù‚ Ø¨ÛŒÙ…Ù‡ Ø³Ù‡Ù… Ú©Ø§Ø±ÙØ±Ù…Ø§ Ú†Ù†Ø¯ Ø¯Ø±ØµØ¯ Ø§Ø³ØªØŸ', 'Ø­Ù‚ Ø¨ÛŒÙ…Ù‡ Ø³Ù‡Ù… Ú©Ø§Ø±Ú¯Ø± Ú†Ù†Ø¯ Ø¯Ø±ØµØ¯ Ø§Ø³ØªØŸ',
    'Ù…Ø±Ø®ØµÛŒ Ø§Ø³ØªØ¹Ù„Ø§Ø¬ÛŒ Ú†Ù†Ø¯ Ø±ÙˆØ² Ø§Ø³ØªØŸ', 'Ù…Ø±Ø®ØµÛŒ Ø²Ø§ÛŒÙ…Ø§Ù† Ú†Ù†Ø¯ Ø±ÙˆØ² Ø§Ø³ØªØŸ',
    'Ù…Ø±Ø®ØµÛŒ Ø³Ø§Ù„Ø§Ù†Ù‡ Ú†Ù†Ø¯ Ø±ÙˆØ² Ø§Ø³ØªØŸ', 'Ø­Ø¯Ø§Ù‚Ù„ Ø¯Ø³ØªÙ…Ø²Ø¯ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ',
    'Ø¹ÛŒØ¯ÛŒ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ', 'Ù¾Ø§Ø¯Ø§Ø´ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ', 'Ø§Ø¶Ø§ÙÙ‡ Ú©Ø§Ø± Ú†Ú¯ÙˆÙ†Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŸ',
    'Ú©Ø³Ø± Ú©Ø§Ø± Ú†Ú¯ÙˆÙ†Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŸ', 'Ù…Ø§Ù„ÛŒØ§Øª Ø­Ù‚ÙˆÙ‚ Ú†Ù†Ø¯ Ø¯Ø±ØµØ¯ Ø§Ø³ØªØŸ',
    'Ø¨ÛŒÙ…Ù‡ ØªÚ©Ù…ÛŒÙ„ÛŒ Ú†ÛŒØ³ØªØŸ', 'Ø¨ÛŒÙ…Ù‡ Ø¹Ù…Ø± Ú†ÛŒØ³ØªØŸ', 'Ø¨ÛŒÙ…Ù‡ Ø­ÙˆØ§Ø¯Ø« Ú†ÛŒØ³ØªØŸ',
    'Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ú©Ø§Ø± Ú†ÛŒØ³ØªØŸ', 'Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ù…ÙˆÙ‚Øª Ú†ÛŒØ³ØªØŸ', 'Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ø¯Ø§Ø¦Ù… Ú†ÛŒØ³ØªØŸ',
    'Ø§Ø®Ø±Ø§Ø¬ Ú†Ú¯ÙˆÙ†Ù‡ Ø§Ø³ØªØŸ', 'Ø§Ø³ØªØ¹ÙØ§ Ú†Ú¯ÙˆÙ†Ù‡ Ø§Ø³ØªØŸ'
]

def generate_jwt():
    """ØªÙˆÙ„ÛŒØ¯ JWT token"""
    payload = {'sub': 'test-user', 'exp': datetime.now(timezone.utc).timestamp() + 3600}
    return jwt.encode(payload, JWT_SECRET, algorithm='HS256')

def test_direct_llm(provider, model, query):
    """ØªØ³Øª Ù…Ø³ØªÙ‚ÛŒÙ… LLM (Ø¨Ø¯ÙˆÙ† RAG)"""
    api_key = OPENAI_KEY if provider == 'openai' else GAPGPT_KEY
    base_url = PROVIDERS[provider]
    
    try:
        start = time.time()
        response = httpx.post(
            f'{base_url}/chat/completions',
            headers={'Authorization': f'Bearer {api_key}', 'Content-Type': 'application/json'},
            json={'model': model, 'messages': [{'role': 'user', 'content': query}]},
            timeout=120.0
        )
        elapsed = (time.time() - start) * 1000
        
        if response.status_code == 200:
            result = response.json()
            return {
                'success': True,
                'time_ms': elapsed,
                'tokens': result['usage']['total_tokens'],
                'answer': result['choices'][0]['message']['content']
            }
        else:
            return {'success': False, 'error': f'HTTP {response.status_code}', 'time_ms': elapsed}
    except Exception as e:
        return {'success': False, 'error': str(e)[:100]}

def test_rag_query(provider, model, query):
    """ØªØ³Øª Ø¨Ø§ RAG (Ø§Ø² Ø·Ø±ÛŒÙ‚ Core API)"""
    token = generate_jwt()
    
    # Ù…ÙˆÙ‚ØªØ§Ù‹ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø±Ø§ ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒÙ…
    # Ø§ÛŒÙ† Ø¨Ø§ÛŒØ¯ Ø§Ø² Ø·Ø±ÛŒÙ‚ environment variable ÛŒØ§ API Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯
    # Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø¯Ú¯ÛŒØŒ ÙÙ‚Ø· Ø²Ù…Ø§Ù† Ø±Ø§ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…
    
    try:
        start = time.time()
        response = httpx.post(
            'http://localhost:7001/api/v1/query/',
            json={
                'query': query,
                'conversation_id': None,
                'language': 'fa',
                'file_attachments': [],
                'enable_web_search': False
            },
            headers={'Authorization': f'Bearer {token}'},
            timeout=120.0
        )
        elapsed = (time.time() - start) * 1000
        
        if response.status_code == 200:
            result = response.json()
            return {
                'success': True,
                'time_ms': elapsed,
                'tokens': result.get('tokens_used', 0),
                'answer': result.get('answer', '')
            }
        else:
            return {'success': False, 'error': f'HTTP {response.status_code}', 'time_ms': elapsed}
    except Exception as e:
        return {'success': False, 'error': str(e)[:100]}

def main():
    print("ğŸš€ Ø´Ø±ÙˆØ¹ ØªØ³Øª Ø¬Ø§Ù…Ø¹ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ LLM")
    print("=" * 70)
    
    results = {
        'classification': {},
        'general': {},
        'business': {}
    }
    
    # ØªØ³Øª Ú©Ù„Ø§Ø³ÛŒÙÛŒÚ©ÛŒØ´Ù† (ÙÙ‚Ø· 5 Ø³ÙˆØ§Ù„ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª)
    print("\nğŸ“Š ØªØ³Øª Ú©Ù„Ø§Ø³ÛŒÙÛŒÚ©ÛŒØ´Ù† (5 Ø³ÙˆØ§Ù„)...")
    for model in ['gpt-5-nano', 'gpt-4o-mini']:
        for provider in ['openai', 'gapgpt']:
            key = f'{provider}_{model}'
            results['classification'][key] = []
            
            for i, query in enumerate(CLASSIFICATION_QUERIES[:5], 1):
                print(f"  {i}/5: {provider} - {model}")
                result = test_direct_llm(provider, model, query)
                results['classification'][key].append(result)
                time.sleep(0.5)
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
    with open('/srv/llm_test_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print("\nâœ… ØªØ³Øª Ú©Ø§Ù…Ù„ Ø´Ø¯. Ù†ØªØ§ÛŒØ¬ Ø¯Ø± /srv/llm_test_results.json Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")

if __name__ == '__main__':
    main()
